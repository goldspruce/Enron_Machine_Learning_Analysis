{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5: The Enron Dataset\n",
    "\n",
    "Robert Lee\n",
    "\n",
    "## The Data Set & Outliers\n",
    "There are 146 people in the Enron Dataset, 21 features each, 18 POI (persons of interest).\n",
    "A tossed out three data points as being unusual artifacts. I did not throw out outliers because they generally seemed to have useful information to identify POIs.\n",
    "\n",
    "## Feature Selection & Engineering\n",
    "I selected 7 features from the original dataset, and created 3 new ones. Looking at correlation to the POI label (from the correlation matrix below), it seems that my new features are not particularly useful for classification. And in fact, 3-5 of best (selectKbest) of the original 7 features seem to be good enough to do the job. If I were to spend more time on this project I would engineer additional features and determine what would be the smallest number of features that would yield good results. Since there was not a huge number of features, I did not do PCA.\n",
    "\n",
    "##  Training & Testing Classifiers\n",
    "As a starting point, I tried NB, DTC, KNN classifiers a few times using different test sizes. NB worked OK, DTC did not, KNN worked well. So I fcoused on KNN for in my grid search. I ran gridSearchCSV with 10, 5, 3, and 1 features with test sizes of 0.3 and 0.1. Of these 10 searches, 5 resulted in classifier 1 and 5 resulted in classifier 2. Classifier 1 had a better F1 score (0.45 vs. 0.37) so I called this my best classifier and wrote it to the pkl file.\n",
    "\n",
    "For reasons discussed here, it seems like it isn't a good idea to use a pipeline to search through a range of selectKbest features:\n",
    "https://discussions.udacity.com/t/selectkbest-pca-and-pipelines/22986/9\n",
    "\n",
    "I suppose I could have written a loop to try to the entire range, but I just picked 10, 5, 3, 1 features as stated above.\n",
    "\n",
    "gridSearchCSV()\n",
    "param_grid = {\"knn__n_neighbors\": [1, 3, 5, 8, 10, 12, 14],\n",
    "              \"knn__algorithm\": [\"auto\",\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "              \"knn__leaf_size\": range(3,10,1),\n",
    "              \"knn__p\": [1,2]\n",
    "             }\n",
    "             \n",
    "Classifier 1\n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=3, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=1, p=1,\n",
    "           weights='uniform')        \n",
    "F1 = 0.45\n",
    "\n",
    "Classifier 2\n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=3, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=1, p=1,\n",
    "           weights='uniform')        \n",
    "F1 = 0.37\n",
    "\n",
    "***\n",
    "\n",
    "I also ran AdaBoost using NB and DTC as the base classifiers (KNN is incompatible with AdaBoost). The resulting classifiers had lower F1 scores than Classifier 1, so I stuck with that one.\n",
    "\n",
    "DTC = DecisionTreeClassifier(random_state = 42, max_features = \"auto\", class_weight = \"balanced\",max_depth = None)\n",
    "ada = AdaBoostClassifier(base_estimator=DTC)\n",
    "\n",
    "param_grid = {\"ada__base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "              \"ada__base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "              \"ada__n_estimators\": [1, 10, 50, 100, 200]\n",
    "             }\n",
    "\n",
    "AdaBoostClassifier(algorithm='SAMME.R',\n",
    "          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impur...dom_state=42, splitter='random'),\n",
    "          learning_rate=1.0, n_estimators=10, random_state=None))])\n",
    "           {'ada__base_estimator__splitter': 'random',\n",
    "           'ada__n_estimators':10'ada__base_estimator__criterion': 'entropy'}\n",
    "F1 = 0.32\n",
    "\n",
    "***\n",
    "\n",
    "NB = GaussianNB()\n",
    "adaN = AdaBoostClassifier(base_estimator=NB)\n",
    "\n",
    "param_grid = {\n",
    "              \"ada__n_estimators\": [1, 10, 50, 100, 200]\n",
    "             }\n",
    "\n",
    "AdaBoostClassifier(algorithm='SAMME.R',\n",
    "          base_estimator=GaussianNB(priors=None), learning_rate=1.0,\n",
    "          n_estimators=1, random_state=None))])\n",
    "          {'ada__n_estimators': 1}\n",
    "          \n",
    "F1 = 0.25\n",
    "\n",
    "## Tuning & Validation\n",
    "\n",
    "By choosing different classifiers and trying parameters, it is possible to get a classifier that works really well (has very high scores) on the test data. This is called tuning, and is part of the art of machine learning. A classifier out of the box may not do a good job of correctly labeling data, but with paramter turning we can improve this.\n",
    "\n",
    "But if we try to optimize too much, we can be guilty of overfitting (overtuning). In fact we could manually create a classifier that perfectly fits the training data with an absurd amount of overfit. Because of possible idiosyncracies and outliers in the training data, it is important to consider possible overfitting.\n",
    "\n",
    "After fitting the classifier on training data, we test (or validate) it with test data before releasing it into the real world. It is a fairly easy thing, with overtuning, to create a classifier that works very well on the training data. But if we don't test the classifer on other data, we may have built a pretty, but useless, classifier. Among other things, outliers in the training data in can skew the classifier fit. Outliers in the testing data can skew the validations scores.\n",
    "\n",
    "Validation can be a bit tricky if there is a limited data, because we don't have much data to train on, much less allocate as between training and test data. This is definitely true of our data set, with only 143 people and 18 POIs). A large number of features relative to the number of data points can be a problem as well, though we can address this to some degree with PCA.\n",
    "\n",
    "Cross validation techniques help us avoid this, by radomly distributing and redistributing data between training and test, we can avoid classifier training problems such as overfitting.\n",
    "\n",
    "I used StratifiedShuffleSplit() with 100 splits. This means that there were 100 randomized train-test splits. The shuffling balances data between training and testing. It also randomzies data that might be ordered. I also could also have used .KFold, but the random shuffling of StratifiedShuffleSplit() is useful because of our small data set.\n",
    "\n",
    "Stratification is the process of distributing class labels relatively evenly between testing and training to prevent bias in either. StratifiedShuffleSplit() and StratifiedKFold() do this for us.\n",
    "\n",
    "## Precision & Recall\n",
    "Since the label is POI:\n",
    "\n",
    "precision = POI true positives / (POI true positives + POI false positives)\n",
    "\n",
    "recall = POI true positives / (POI true positives + POI false negatives)\n",
    "\n",
    "Thus if our classifier identified 10 POIs, with 5 true positives and 5 false positives, precision would be 0.5\n",
    "\n",
    "If the ground state truth was 12 POIs, where we correctly identified 5 but 7 were false negatives, our recall also would be 0.42\n",
    "\n",
    "F1 is a score that balances precision against recall\n",
    "F1 = 2 (precision * recall) / precision + recall\n",
    "\n",
    "In the above example F1 = 0.46\n",
    "\n",
    "Sometimes we don't want to balance them in this way, in that the consequences of a false positive vs false negative are asymmetric. We might want a higher precision at the expense of recall or vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertlee/anaconda/envs/py2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/robertlee/anaconda/envs/py2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import grid_search \n",
    "from time import time\n",
    "\n",
    "from sklearn import svm, cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from tester import test_classifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi','salary','total_stock_value','exercised_stock_options','from_poi_to_this_person','from_this_person_to_poi','from_messages','to_messages','ratio_to_poi','ratio_from_poi','ratio_exercised']\n",
    "# You will need to use more features, 8 existing features, 3 new ones I created\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "\n",
    "I use 8 existing features, and create 3 more (the last 3), combining them to create a list of 11 features. The first feature is the label, poi, so really there are just 10 features in play.\n",
    "\n",
    "features_old = ['poi','salary','total_stock_value','exercised_stock_options','from_poi_to_this_person','from_this_person_to_poi','from_messages','to_messages','ratio_to_poi','ratio_from_poi']\n",
    "\n",
    "features_new = ['ratio_to_poi','ratio_from_poi','ratio_exercised']\n",
    "\n",
    "features_list = features_old + features_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poi',\n",
       " 'salary',\n",
       " 'total_stock_value',\n",
       " 'exercised_stock_options',\n",
       " 'from_poi_to_this_person',\n",
       " 'from_this_person_to_poi',\n",
       " 'from_messages',\n",
       " 'to_messages',\n",
       " 'ratio_to_poi',\n",
       " 'ratio_from_poi',\n",
       " 'ratio_exercised']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_old = ['poi','salary','total_stock_value','exercised_stock_options','from_poi_to_this_person','from_this_person_to_poi','from_messages','to_messages']\n",
    "features_new = ['poi','ratio_to_poi','ratio_from_poi','ratio_exercised']\n",
    "features_list = features_old + features_new\n",
    "features_list.pop(8)\n",
    "features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is one entry in the dictionary, key: 'ALLEN PHILLIP K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bonus': 4175000,\n",
      " 'deferral_payments': 2869717,\n",
      " 'deferred_income': -3081055,\n",
      " 'director_fees': 'NaN',\n",
      " 'email_address': 'phillip.allen@enron.com',\n",
      " 'exercised_stock_options': 1729541,\n",
      " 'expenses': 13868,\n",
      " 'from_messages': 2195,\n",
      " 'from_poi_to_this_person': 47,\n",
      " 'from_this_person_to_poi': 65,\n",
      " 'loan_advances': 'NaN',\n",
      " 'long_term_incentive': 304805,\n",
      " 'other': 152,\n",
      " 'poi': False,\n",
      " 'restricted_stock': 126027,\n",
      " 'restricted_stock_deferred': -126027,\n",
      " 'salary': 201955,\n",
      " 'shared_receipt_with_poi': 1407,\n",
      " 'to_messages': 2902,\n",
      " 'total_payments': 4484442,\n",
      " 'total_stock_value': 1729541}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(data_dict['ALLEN PHILLIP K'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length of dictionary (number of people) and length of one of the entries == # of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print len(data_dict)\n",
    "print len(data_dict['ALLEN PHILLIP K'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Remove outliers\n",
    "\n",
    "Three of the \"people\" in the dictionary are not people, but bad data to be removed\n",
    "\n",
    "\"TOTAL\" appears to be a summary statistic.\n",
    "\"TRAVEL AGENCY IN THE PARK\" appears to be a contractor that was paid a sum of money.\n",
    "\"LOCKHART EUGENE E\" has all NaN values. Harmless, but I go ahead and remove it.\n",
    "\n",
    "I don't remove data outliers, because they are probably important data (the big shot executives making a lot of money and communicating a lot with each other)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three entries popped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.pop('TOTAL', 0)\n",
    "data_dict.pop('TRAVEL AGENCY IN THE PAR', 0)\n",
    "data_dict.pop('LOCKHART EUGENE E', 0)\n",
    "print \"Three entries popped\"\n",
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I look for 'poi = TRUE to count the number of persons of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "for each in data_dict:\n",
    "    if data_dict[each]['poi']:\n",
    "        n+=1\n",
    "print n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Create new feature(s)\n",
    "The 3 new features I create are:\n",
    "ratio_exercised, ratio_to_poi, ratio_from_poi\n",
    "\n",
    "(1) ratio_exercised = exercised_stock_options / total_stock_value\n",
    "I created this feature to reflect how much stock the person exercised out of their total (from 0 to 1). I figured that people who were in on the scam might have exercised more of their options, knowing that it was a house of cards. On the other hand, a middle-class person who was not in on the scam might also exercise their options, given the high share price (honest desire to cash in).\n",
    "\n",
    "(2) ratio_to_poi = from_this_person_to_poi / to_messages\n",
    "Another 0 to 1 ratio. The absolute number of emails to a POI is less meaningful than the ratio of their messages to POI.\n",
    "\n",
    "(3) ratio_to_poi = from_poi_to_this_person / from_messages\n",
    "Another 0 to 1 ratio. The absolute number of emails from a POI is less meaningful than the ratio of messages from a POI.\n",
    "\n",
    "I am aware that there might be data leakage issues regarding from_this_person_to_poi and from_poi_to_this_person, and thus any features derived from them, but it is not abssolutely clear that this is the case, so I will accept that they are OK features to use for purposes of this assignment.\n",
    "\n",
    "I first eliminate NaN and bad values (any of numerator < 0, any denominator <= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def new_feature(numerator,denominator):\n",
    "    new_feature=[]\n",
    "\n",
    "    for i in data_dict:\n",
    "        if data_dict[i][numerator]==\"NaN\" or data_dict[i][denominator]==\"NaN\":\n",
    "            new_feature.append(\"NaN\")\n",
    "        elif data_dict[i][numerator]<0 or data_dict[i][denominator]<=0:\n",
    "            new_feature.append(\"NaN\")\n",
    "        else:\n",
    "            new_feature.append(float(data_dict[i][numerator]) / data_dict[i][denominator])\n",
    "    return new_feature\n",
    "\n",
    "### create lists of new features\n",
    "ratio_exercised=new_feature(\"exercised_stock_options\",\"total_stock_value\")\n",
    "ratio_to_poi=new_feature(\"from_poi_to_this_person\",\"to_messages\")\n",
    "ratio_from_poi=new_feature(\"from_this_person_to_poi\",\"from_messages\")\n",
    "\n",
    "### insert new features into data_dict\n",
    "count=0\n",
    "for i in data_dict:\n",
    "    data_dict[i][\"ratio_exercised\"] = ratio_exercised[count]\n",
    "    data_dict[i][\"ratio_to_poi\"] = ratio_to_poi[count]\n",
    "    data_dict[i][\"ratio_from_poi\"] = ratio_from_poi[count]\n",
    "    count +=1\n",
    "\n",
    "### store to my_dataset for easy export below\n",
    "my_dataset = data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot new features to get a feel for them\n",
    "## ratio_exercised\n",
    "\n",
    "Ratio of stock options exercised is betwen 0 (none exercised) up to about 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b9c9bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=0\n",
    "for point in data:\n",
    "    ratio_exercised = point[8]\n",
    "    plt.scatter( n, ratio_exercised )\n",
    "    n+=1\n",
    "plt.xlabel(\"ratio exercised\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ratio_to_poi\n",
    "\n",
    "Ratio of all emails sent to POI\n",
    "\n",
    "Between 0 and 1.0.\n",
    "\n",
    "The one 1.0 data point is suspiciously high, so I print one that point above the plot. This person was not a PIO, had a salary of 130K, had significant stock, sent 10 emails to POI, received 17 emails from POI, sent 17 total emails, and received 128 total emails. So this data point does not seem outlanding. In addition, since this feature is not in my top 5 best (see below), I am not too concerned with this 1.0 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.00000000e+00   1.30724000e+05   2.28276800e+06   2.28276800e+06\n",
      "   1.00000000e+01   1.70000000e+01   1.70000000e+01   1.28000000e+02\n",
      "   7.81250000e-02   1.00000000e+00   1.00000000e+00]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f0b6ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=0\n",
    "for point in data:\n",
    "    ratio_to_poi  = point[9]\n",
    "    if ratio_to_poi == 1.0:\n",
    "        print point\n",
    "    plt.scatter( n, ratio_to_poi )\n",
    "    n+=1\n",
    "plt.xlabel(\"ratio of all emails sent to POI\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ratio_from_poi\n",
    "\n",
    "Ratio of all emails from POI\n",
    "\n",
    "Between 0 and 1.0.\n",
    "\n",
    "There are a lot of 1.0 data points. So either the data is generally pretty bad, or else these 1.0 values are valid. I'll go with the latter assumption, though of course I could investigate more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f0b6310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=0\n",
    "for point in data:\n",
    "    ratio_from_poi  = point[10]\n",
    "    plt.scatter( n, ratio_from_poi )\n",
    "    n+=1\n",
    "plt.xlabel(\"ratio of all from POI\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I print a correlation matrix to get a sense of feature correlation with the labels (row/column 0)\n",
    "\n",
    "Of the 3 new features, 8,9,10, only 9, ratio_from_poi has a fairly strong correlation, 0.31. Thus one could argue that is the only new feature worth looking at. But for sake of academic exercise, rather than trying to engineer additional new features, I'll continue with these.\n",
    "\n",
    "Of the original 7 features, 1,2,3 all have correlations to the label above 0.3. These are the 3 best features, and 9, above, is the forth best. None of the other features are even close in terms of correlation. Thus one could argue that we should only use these 3 or 4 features.\n",
    "\n",
    "Not surprisingly, the first three features, all related to money, are highly correlated to each other with 2 and 3 being correlated at 0.96. Thus 2 and 3 in particular would be amendable to PCA to reduce the number of features. For the scope of this project, though, PCA didn't seem necessary, as we are already working with a small number of features, so I did not do PCA.\n",
    "\n",
    "1 salary\n",
    "2 total_stock_value\n",
    "3 exercised_stock_options\n",
    "9 ratio_from_poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 poi\n",
      "1 salary\n",
      "2 total_stock_value\n",
      "3 exercised_stock_options\n",
      "4 from_poi_to_this_person\n",
      "5 from_this_person_to_poi\n",
      "6 from_messages\n",
      "7 to_messages\n",
      "8 ratio_to_poi\n",
      "9 ratio_from_poi\n",
      "10 ratio_exercised\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323062</td>\n",
       "      <td>0.373375</td>\n",
       "      <td>0.378329</td>\n",
       "      <td>0.175804</td>\n",
       "      <td>0.120282</td>\n",
       "      <td>-0.043027</td>\n",
       "      <td>0.091524</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.310498</td>\n",
       "      <td>-0.063065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.323062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.507512</td>\n",
       "      <td>0.434179</td>\n",
       "      <td>0.382845</td>\n",
       "      <td>0.188981</td>\n",
       "      <td>0.128107</td>\n",
       "      <td>0.369150</td>\n",
       "      <td>0.214900</td>\n",
       "      <td>0.271439</td>\n",
       "      <td>-0.020504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.373375</td>\n",
       "      <td>0.507512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963300</td>\n",
       "      <td>0.118218</td>\n",
       "      <td>0.008916</td>\n",
       "      <td>-0.022347</td>\n",
       "      <td>0.097094</td>\n",
       "      <td>-0.008048</td>\n",
       "      <td>0.101619</td>\n",
       "      <td>0.212430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.378329</td>\n",
       "      <td>0.434179</td>\n",
       "      <td>0.963300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.107552</td>\n",
       "      <td>-0.009687</td>\n",
       "      <td>-0.033640</td>\n",
       "      <td>0.065464</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>0.088343</td>\n",
       "      <td>0.290629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.175804</td>\n",
       "      <td>0.382845</td>\n",
       "      <td>0.118218</td>\n",
       "      <td>0.107552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491520</td>\n",
       "      <td>0.245550</td>\n",
       "      <td>0.608153</td>\n",
       "      <td>0.571588</td>\n",
       "      <td>0.237443</td>\n",
       "      <td>0.006517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.120282</td>\n",
       "      <td>0.188981</td>\n",
       "      <td>0.008916</td>\n",
       "      <td>-0.009687</td>\n",
       "      <td>0.491520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606896</td>\n",
       "      <td>0.600738</td>\n",
       "      <td>0.070609</td>\n",
       "      <td>0.069135</td>\n",
       "      <td>-0.007351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.043027</td>\n",
       "      <td>0.128107</td>\n",
       "      <td>-0.022347</td>\n",
       "      <td>-0.033640</td>\n",
       "      <td>0.245550</td>\n",
       "      <td>0.606896</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.504045</td>\n",
       "      <td>-0.018426</td>\n",
       "      <td>-0.072205</td>\n",
       "      <td>0.047233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.091524</td>\n",
       "      <td>0.369150</td>\n",
       "      <td>0.097094</td>\n",
       "      <td>0.065464</td>\n",
       "      <td>0.608153</td>\n",
       "      <td>0.600738</td>\n",
       "      <td>0.504045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.103680</td>\n",
       "      <td>0.096925</td>\n",
       "      <td>-0.013960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.214900</td>\n",
       "      <td>-0.008048</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>0.571588</td>\n",
       "      <td>0.070609</td>\n",
       "      <td>-0.018426</td>\n",
       "      <td>0.103680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.470755</td>\n",
       "      <td>-0.052790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.310498</td>\n",
       "      <td>0.271439</td>\n",
       "      <td>0.101619</td>\n",
       "      <td>0.088343</td>\n",
       "      <td>0.237443</td>\n",
       "      <td>0.069135</td>\n",
       "      <td>-0.072205</td>\n",
       "      <td>0.096925</td>\n",
       "      <td>0.470755</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.063065</td>\n",
       "      <td>-0.020504</td>\n",
       "      <td>0.212430</td>\n",
       "      <td>0.290629</td>\n",
       "      <td>0.006517</td>\n",
       "      <td>-0.007351</td>\n",
       "      <td>0.047233</td>\n",
       "      <td>-0.013960</td>\n",
       "      <td>-0.052790</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   1.000000  0.323062  0.373375  0.378329  0.175804  0.120282 -0.043027   \n",
       "1   0.323062  1.000000  0.507512  0.434179  0.382845  0.188981  0.128107   \n",
       "2   0.373375  0.507512  1.000000  0.963300  0.118218  0.008916 -0.022347   \n",
       "3   0.378329  0.434179  0.963300  1.000000  0.107552 -0.009687 -0.033640   \n",
       "4   0.175804  0.382845  0.118218  0.107552  1.000000  0.491520  0.245550   \n",
       "5   0.120282  0.188981  0.008916 -0.009687  0.491520  1.000000  0.606896   \n",
       "6  -0.043027  0.128107 -0.022347 -0.033640  0.245550  0.606896  1.000000   \n",
       "7   0.091524  0.369150  0.097094  0.065464  0.608153  0.600738  0.504045   \n",
       "8   0.130400  0.214900 -0.008048 -0.000078  0.571588  0.070609 -0.018426   \n",
       "9   0.310498  0.271439  0.101619  0.088343  0.237443  0.069135 -0.072205   \n",
       "10 -0.063065 -0.020504  0.212430  0.290629  0.006517 -0.007351  0.047233   \n",
       "\n",
       "          7         8         9         10  \n",
       "0   0.091524  0.130400  0.310498 -0.063065  \n",
       "1   0.369150  0.214900  0.271439 -0.020504  \n",
       "2   0.097094 -0.008048  0.101619  0.212430  \n",
       "3   0.065464 -0.000078  0.088343  0.290629  \n",
       "4   0.608153  0.571588  0.237443  0.006517  \n",
       "5   0.600738  0.070609  0.069135 -0.007351  \n",
       "6   0.504045 -0.018426 -0.072205  0.047233  \n",
       "7   1.000000  0.103680  0.096925 -0.013960  \n",
       "8   0.103680  1.000000  0.470755 -0.052790  \n",
       "9   0.096925  0.470755  1.000000  0.005317  \n",
       "10 -0.013960 -0.052790  0.005317  1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=0\n",
    "for feature in features_list:\n",
    "    print n,feature\n",
    "    n+=1\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "df.corr()\n",
    "#for each in np.corrcoef(data):\n",
    " #   print each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out a few classifiers\n",
    "Rather than use systematic cross-validation and classifier search with gridSearchCSV, for now I simply try some classifiers on three sizes, just to get a feel: 0.1, 0.3, 0.5\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels, test_size=X, random_state=42)\n",
    "\n",
    "Since there are only 18 POIs, we can only go so small with the test size before we don't get any POIs. 0.1 is probably about the smallest we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_train1, features_test1, labels_train1, labels_test1 = cross_validation.train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "features_train3, features_test3, labels_train3, labels_test3 = cross_validation.train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "features_train5, features_test5, labels_train5, labels_test5 = cross_validation.train_test_split(features, labels, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying NB with the above features and test sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify_NB(features_train, labels_train):\n",
    "    \n",
    "    ### your code goes here--should return a trained decision tree classifer\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    clf.fit(features_train, labels_train)\n",
    "    return clf\n",
    "\n",
    "def class_run(features_train, labels_train, features_test, labels_test):\n",
    "    clf = classify_NB(features_train, labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "    return {\"Accuracy\":accuracy_score(pred,labels_test),\\\n",
    "                          \"Precision\":precision_score(pred,labels_test),\\\n",
    "                          \"Recall\":recall_score(pred,labels_test),\\\n",
    "                          \"F1\":f1_score(pred,labels_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all 10 features (plus poi label)\n",
      "NB: 0.1 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.4\n",
      "Precision  :  0.333333333333\n",
      "Accuracy  :  0.785714285714\n",
      "\n",
      "NB: 0.3 test size\n",
      "Recall  :  0.75\n",
      "F1  :  0.6\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.9\n",
      "\n",
      "NB: 0.5 test size\n",
      "Recall  :  0.333333333333\n",
      "F1  :  0.4\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.863636363636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"all 10 features (plus poi label)\"\n",
    "def print_it(title,input):\n",
    "    print title\n",
    "    answer = input\n",
    "    for each in answer:\n",
    "        print each,\" : \",answer[each]\n",
    "    print\n",
    "\n",
    "print_it(\"NB: 0.1 test size\",class_run(features_train1, labels_train1, features_test1, labels_test1))\n",
    "print_it(\"NB: 0.3 test size\",class_run(features_train3, labels_train3, features_test3, labels_test3))\n",
    "print_it(\"NB: 0.5 test size\",class_run(features_train5, labels_train5, features_test5, labels_test5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying NB with different subsets of the features\n",
    "\n",
    "features_list contains all 11 features (8 original, 3 new)\n",
    "\n",
    "I create these subset feature lists as well\n",
    "\n",
    "Each must contain the first feature, poi\n",
    "\n",
    "features_old = poi + the original 7\n",
    "\n",
    "features_new = poi + the 3 new ones\n",
    "\n",
    "features_first = poi + 1,2,3   ($ related)\n",
    "\n",
    "features_second = poi + 4,5,6,7 (email related)\n",
    "\n",
    "features_F = features_first + 'ratio_exercised' ($ related)\n",
    "\n",
    "features_E = features_second + ratio_to_poi' + 'ratio_from_poi' (email related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_first = ['poi','salary','total_stock_value','exercised_stock_options']\n",
    "features_second = ['poi','from_poi_to_this_person','from_this_person_to_poi','from_messages','to_messages','ratio_to_poi','ratio_from_poi','ratio_exercised']\n",
    "features_F = ['poi','salary','total_stock_value','exercised_stock_options','ratio_exercised']\n",
    "features_E = ['poi','from_poi_to_this_person','from_this_person_to_poi','from_messages','to_messages','ratio_to_poi','ratio_from_poi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the original 7 features yields the same results as using all 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_old = the original 7\n",
      "\n",
      "NB: 0.1 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.4\n",
      "Precision  :  0.333333333333\n",
      "Accuracy  :  0.785714285714\n",
      "\n",
      "NB: 0.3 test size\n",
      "Recall  :  0.75\n",
      "F1  :  0.6\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.9\n",
      "\n",
      "NB: 0.5 test size\n",
      "Recall  :  0.333333333333\n",
      "F1  :  0.4\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.863636363636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = featureFormat(my_dataset, features_old, sort_keys = True)\n",
    "\n",
    "labels, features_o = targetFeatureSplit(data)\n",
    "features_train1o, features_test1o, labels_train1o, labels_test1o = cross_validation.train_test_split(features_o, labels, test_size=0.1, random_state=42)\n",
    "features_train3o, features_test3o, labels_train3o, labels_test3o = cross_validation.train_test_split(features_o, labels, test_size=0.3, random_state=42)\n",
    "features_train5o, features_test5o, labels_train5o, labels_test5o = cross_validation.train_test_split(features_o, labels, test_size=0.5, random_state=42)\n",
    "\n",
    "print \"features_old = the original 7\"\n",
    "print\n",
    "print_it(\"NB: 0.1 test size\",class_run(features_train1o, labels_train1o, features_test1o, labels_test1o))\n",
    "print_it(\"NB: 0.3 test size\",class_run(features_train3o, labels_train3o, features_test3o, labels_test3o))\n",
    "print_it(\"NB: 0.5 test size\",class_run(features_train5o, labels_train5o, features_test5o, labels_test5o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using just the 3 new features doesn't work as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_new = poi + 3 new features\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertlee/anaconda/envs/py2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/robertlee/anaconda/envs/py2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: 0.1 test size\n",
      "Recall  :  0.0\n",
      "F1  :  0.0\n",
      "Precision  :  0.0\n",
      "Accuracy  :  0.833333333333\n",
      "\n",
      "NB: 0.3 test size\n",
      "Recall  :  0.333333333333\n",
      "F1  :  0.25\n",
      "Precision  :  0.2\n",
      "Accuracy  :  0.833333333333\n",
      "\n",
      "NB: 0.5 test size\n",
      "Recall  :  0.0\n",
      "F1  :  0.0\n",
      "Precision  :  0.0\n",
      "Accuracy  :  0.830508474576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_n = featureFormat(my_dataset, features_new, sort_keys = True)\n",
    "labels, features_n = targetFeatureSplit(data_n)\n",
    "features_train1n, features_test1n, labels_train1n, labels_test1n = cross_validation.train_test_split(features_n, labels, test_size=0.1, random_state=42)\n",
    "features_train3n, features_test3n, labels_train3n, labels_test3n = cross_validation.train_test_split(features_n, labels, test_size=0.3, random_state=42)\n",
    "features_train5n, features_test5n, labels_train5n, labels_test5n = cross_validation.train_test_split(features_n, labels, test_size=0.5, random_state=42)\n",
    "\n",
    "print \"features_new = poi + 3 new features\"\n",
    "print\n",
    "print_it(\"NB: 0.1 test size\",class_run(features_train1n, labels_train1n, features_test1n, labels_test1n))\n",
    "print_it(\"NB: 0.3 test size\",class_run(features_train3n, labels_train3n, features_test3n, labels_test3n))\n",
    "print_it(\"NB: 0.5 test size\",class_run(features_train5n, labels_train5n, features_test5n, labels_test5n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neither does using just money related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_first = poi + 1,2,3   ($ related)\n",
      "\n",
      "NB: 0.1 test size\n",
      "Recall  :  0.0\n",
      "F1  :  0.0\n",
      "Precision  :  0.0\n",
      "Accuracy  :  0.846153846154\n",
      "\n",
      "NB: 0.3 test size\n",
      "Recall  :  0.0\n",
      "F1  :  0.0\n",
      "Precision  :  0.0\n",
      "Accuracy  :  0.871794871795\n",
      "\n",
      "NB: 0.5 test size\n",
      "Recall  :  0.25\n",
      "F1  :  0.181818181818\n",
      "Precision  :  0.142857142857\n",
      "Accuracy  :  0.861538461538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_f = featureFormat(my_dataset, features_first, sort_keys = True)\n",
    "labels, features_f = targetFeatureSplit(data_f)\n",
    "features_train1f, features_test1f, labels_train1f, labels_test1f = cross_validation.train_test_split(features_f, labels, test_size=0.1, random_state=42)\n",
    "features_train3f, features_test3f, labels_train3f, labels_test3f = cross_validation.train_test_split(features_f, labels, test_size=0.3, random_state=42)\n",
    "features_train5f, features_test5f, labels_train5f, labels_test5f = cross_validation.train_test_split(features_f, labels, test_size=0.5, random_state=42)\n",
    "\n",
    "print \"features_first = poi + 1,2,3   ($ related)\"\n",
    "print\n",
    "print_it(\"NB: 0.1 test size\",class_run(features_train1f, labels_train1f, features_test1f, labels_test1f))\n",
    "print_it(\"NB: 0.3 test size\",class_run(features_train3f, labels_train3f, features_test3f, labels_test3f))\n",
    "print_it(\"NB: 0.5 test size\",class_run(features_train5f, labels_train5f, features_test5f, labels_test5f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nor just email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poi + 4,5,6,7 (email related)\n",
      "\n",
      "NB: 0.1 test size\n",
      "Recall  :  0.0\n",
      "F1  :  0.0\n",
      "Precision  :  0.0\n",
      "Accuracy  :  0.833333333333\n",
      "\n",
      "NB: 0.3 test size\n",
      "Recall  :  0.272727272727\n",
      "F1  :  0.352941176471\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.694444444444\n",
      "\n",
      "NB: 0.5 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.444444444444\n",
      "Precision  :  0.4\n",
      "Accuracy  :  0.833333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_s = featureFormat(my_dataset, features_second, sort_keys = True)\n",
    "labels, features_s = targetFeatureSplit(data_s)\n",
    "features_train1s, features_test1s, labels_train1s, labels_test1s = cross_validation.train_test_split(features_s, labels, test_size=0.1, random_state=42)\n",
    "features_train3s, features_test3s, labels_train3s, labels_test3s = cross_validation.train_test_split(features_s, labels, test_size=0.3, random_state=42)\n",
    "features_train5s, features_test5s, labels_train5s, labels_test5s = cross_validation.train_test_split(features_s, labels, test_size=0.5, random_state=42)\n",
    "\n",
    "print \"poi + 4,5,6,7 (email related)\"\n",
    "print\n",
    "print_it(\"NB: 0.1 test size\",class_run(features_train1s, labels_train1s, features_test1s, labels_test1s))\n",
    "print_it(\"NB: 0.3 test size\",class_run(features_train3s, labels_train3s, features_test3s, labels_test3s))\n",
    "print_it(\"NB: 0.5 test size\",class_run(features_train5s, labels_train5s, features_test5s, labels_test5s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now I'll run SelectKBest on k=1 through k=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest() best features, k = 9\n",
      "\n",
      "NB: 0.1 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.4\n",
      "Precision  :  0.333333333333\n",
      "Accuracy  :  0.785714285714\n",
      "\n",
      "NB: 0.3 test size\n",
      "Recall  :  0.75\n",
      "F1  :  0.6\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.9\n",
      "\n",
      "NB: 0.5 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.5\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.909090909091\n",
      "\n",
      "SelectKBest() best features, k = 8\n",
      "\n",
      "NB: 0.1 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.4\n",
      "Precision  :  0.333333333333\n",
      "Accuracy  :  0.785714285714\n",
      "\n",
      "NB: 0.3 test size\n",
      "Recall  :  0.75\n",
      "F1  :  0.6\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.9\n",
      "\n",
      "NB: 0.5 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.5\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.909090909091\n",
      "\n",
      "SelectKBest() best features, k = 7\n",
      "\n",
      "NB: 0.1 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.4\n",
      "Precision  :  0.333333333333\n",
      "Accuracy  :  0.785714285714\n",
      "\n",
      "NB: 0.3 test size\n",
      "Recall  :  0.75\n",
      "F1  :  0.6\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.9\n",
      "\n",
      "NB: 0.5 test size\n",
      "Recall  :  0.428571428571\n",
      "F1  :  0.461538461538\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.893939393939\n",
      "\n",
      "SelectKBest() best features, k = 6\n",
      "\n",
      "NB: 0.1 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.4\n",
      "Precision  :  0.333333333333\n",
      "Accuracy  :  0.785714285714\n",
      "\n",
      "NB: 0.3 test size\n",
      "Recall  :  0.75\n",
      "F1  :  0.6\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.9\n",
      "\n",
      "NB: 0.5 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.5\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.909090909091\n",
      "\n",
      "SelectKBest() best features, k = 5\n",
      "\n",
      "NB: 0.1 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.4\n",
      "Precision  :  0.333333333333\n",
      "Accuracy  :  0.785714285714\n",
      "\n",
      "NB: 0.3 test size\n",
      "Recall  :  0.75\n",
      "F1  :  0.6\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.9\n",
      "\n",
      "NB: 0.5 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.5\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.909090909091\n",
      "\n",
      "SelectKBest() best features, k = 4\n",
      "\n",
      "NB: 0.1 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.4\n",
      "Precision  :  0.333333333333\n",
      "Accuracy  :  0.785714285714\n",
      "\n",
      "NB: 0.3 test size\n",
      "Recall  :  0.75\n",
      "F1  :  0.6\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.9\n",
      "\n",
      "NB: 0.5 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.5\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.909090909091\n",
      "\n",
      "SelectKBest() best features, k = 3\n",
      "\n",
      "NB: 0.1 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.4\n",
      "Precision  :  0.333333333333\n",
      "Accuracy  :  0.785714285714\n",
      "\n",
      "NB: 0.3 test size\n",
      "Recall  :  0.75\n",
      "F1  :  0.6\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.9\n",
      "\n",
      "NB: 0.5 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.5\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.909090909091\n",
      "\n",
      "SelectKBest() best features, k = 2\n",
      "\n",
      "NB: 0.1 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.4\n",
      "Precision  :  0.333333333333\n",
      "Accuracy  :  0.785714285714\n",
      "\n",
      "NB: 0.3 test size\n",
      "Recall  :  0.75\n",
      "F1  :  0.6\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.9\n",
      "\n",
      "NB: 0.5 test size\n",
      "Recall  :  0.428571428571\n",
      "F1  :  0.461538461538\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.893939393939\n",
      "\n",
      "SelectKBest() best features, k = 1\n",
      "\n",
      "NB: 0.1 test size\n",
      "Recall  :  1.0\n",
      "F1  :  0.5\n",
      "Precision  :  0.333333333333\n",
      "Accuracy  :  0.857142857143\n",
      "\n",
      "NB: 0.3 test size\n",
      "Recall  :  1.0\n",
      "F1  :  0.666666666667\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.925\n",
      "\n",
      "NB: 0.5 test size\n",
      "Recall  :  0.5\n",
      "F1  :  0.5\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.909090909091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "for n in range (9,0,-1):\n",
    "    print \"SelectKBest() best features, k =\",n\n",
    "    data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "    labels, features_n = targetFeatureSplit(data)\n",
    "    K_best_n = SelectKBest(k=n)\n",
    "    features_Kbest_n = K_best_n.fit_transform(features_n, labels)\n",
    "\n",
    "    features_train1, features_test1, labels_train1, labels_test1 = cross_validation.train_test_split(features_Kbest_n, labels, test_size=0.1, random_state=42)\n",
    "    features_train3, features_test3, labels_train3, labels_test3 = cross_validation.train_test_split(features_Kbest_n, labels, test_size=0.3, random_state=42)\n",
    "    features_train5, features_test5, labels_train5, labels_test5 = cross_validation.train_test_split(features_Kbest_n, labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    print\n",
    "    ts1 = class_run(features_train1, labels_train1, features_test1, labels_test1)\n",
    "    ts3 = class_run(features_train3, labels_train3, features_test3, labels_test3)\n",
    "    ts5 = class_run(features_train5, labels_train5, features_test5, labels_test5)\n",
    "    \n",
    "    print_it(\"NB: 0.1 test size\",ts1)\n",
    "    print_it(\"NB: 0.3 test size\",ts3)\n",
    "    print_it(\"NB: 0.5 test size\",ts5)\n",
    "    \n",
    "    acc.append(ts5[\"Accuracy\"])\n",
    "    precision.append(ts5[\"Recall\"])\n",
    "    recall.append(ts5[\"Precision\"])\n",
    "    f1.append(ts5[\"F1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above feature investigations\n",
    "I stored the scores for test_size=0.5 and print them below.\n",
    "We get pretty much the same results whether we use 9 feaures or 1.  The best feature is the original feature of salary, perhaps this is enough. It sounds intuitively reasonable that salary predicts POI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies\n",
      "[0.90909090909090906, 0.90909090909090906, 0.89393939393939392, 0.90909090909090906, 0.90909090909090906, 0.90909090909090906, 0.90909090909090906, 0.89393939393939392, 0.90909090909090906]\n",
      "Precisions\n",
      "[0.5, 0.5, 0.42857142857142855, 0.5, 0.5, 0.5, 0.5, 0.42857142857142855, 0.5]\n",
      "Recalls\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "F1s\n",
      "[0.5, 0.5, 0.46153846153846151, 0.5, 0.5, 0.5, 0.5, 0.46153846153846151, 0.5]\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracies\"\n",
    "print acc\n",
    "print \"Precisions\"\n",
    "print precision\n",
    "print \"Recalls\"\n",
    "print recall\n",
    "print \"F1s\"\n",
    "print f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying KNN() with 3 neighbors\n",
    "I stored the scores for test_size=0.5 and print them below.\n",
    "Again, we get similar results whether we use 10 features all the way to just 1, salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 10 features, KNN, k=3\n",
      "\n",
      "KNN: 0.1 test size\n",
      "Recall  :  1.0\n",
      "F1  :  0.5\n",
      "Precision  :  0.333333333333\n",
      "Accuracy  :  0.857142857143\n",
      "\n",
      "KNN: 0.3 test size\n",
      "Recall  :  0.0\n",
      "F1  :  0.0\n",
      "Precision  :  0.0\n",
      "Accuracy  :  0.825\n",
      "\n",
      "KNN: 0.5 test size\n",
      "Recall  :  0.375\n",
      "F1  :  0.428571428571\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.878787878788\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def classify_KNN(features_train, labels_train):\n",
    "    \n",
    "    ### your code goes here--should return a trained decision tree classifer\n",
    "    \n",
    "    clf = KNeighborsClassifier(3)\n",
    "    clf.fit(features_train, labels_train)\n",
    "    return clf\n",
    "\n",
    "def class_run_KNN(features_train, labels_train, features_test, labels_test):\n",
    "    clf = classify_KNN(features_train, labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "    return {\"Accuracy\":accuracy_score(pred,labels_test),\\\n",
    "                          \"Precision\":precision_score(pred,labels_test),\\\n",
    "                          \"Recall\":recall_score(pred,labels_test),\\\n",
    "                          \"F1\":f1_score(pred,labels_test)}\n",
    "\n",
    "print \"All 10 features, KNN, k=3\"\n",
    "print\n",
    "print_it(\"KNN: 0.1 test size\",class_run_KNN(features_train1, labels_train1, features_test1, labels_test1))\n",
    "print_it(\"KNN: 0.3 test size\",class_run_KNN(features_train3, labels_train3, features_test3, labels_test3))\n",
    "print_it(\"KNN: 0.5 test size\",class_run_KNN(features_train5, labels_train5, features_test5, labels_test5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest() best features, k = 9\n",
      "\n",
      "KNN: 0.1 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "KNN: 0.3 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "KNN: 0.5 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "SelectKBest() best features, k = 8\n",
      "\n",
      "KNN: 0.1 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "KNN: 0.3 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "KNN: 0.5 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "SelectKBest() best features, k = 7\n",
      "\n",
      "KNN: 0.1 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "KNN: 0.3 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "KNN: 0.5 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "SelectKBest() best features, k = 6\n",
      "\n",
      "KNN: 0.1 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "KNN: 0.3 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "KNN: 0.5 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "SelectKBest() best features, k = 5\n",
      "\n",
      "KNN: 0.1 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "KNN: 0.3 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "KNN: 0.5 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "SelectKBest() best features, k = 4\n",
      "\n",
      "KNN: 0.1 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "KNN: 0.3 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "KNN: 0.5 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "SelectKBest() best features, k = 3\n",
      "\n",
      "KNN: 0.1 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "KNN: 0.3 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "KNN: 0.5 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "SelectKBest() best features, k = 2\n",
      "\n",
      "KNN: 0.1 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "KNN: 0.3 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "KNN: 0.5 test size\n",
      "Recall  :  0.6\n",
      "F1  :  0.545454545455\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.924242424242\n",
      "\n",
      "SelectKBest() best features, k = 1\n",
      "\n",
      "KNN: 0.1 test size\n",
      "Recall  :  0.375\n",
      "F1  :  0.428571428571\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.878787878788\n",
      "\n",
      "KNN: 0.3 test size\n",
      "Recall  :  0.375\n",
      "F1  :  0.428571428571\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.878787878788\n",
      "\n",
      "KNN: 0.5 test size\n",
      "Recall  :  0.375\n",
      "F1  :  0.428571428571\n",
      "Precision  :  0.5\n",
      "Accuracy  :  0.878787878788\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "for n in range (9,0,-1):\n",
    "    print \"SelectKBest() best features, k =\",n\n",
    "    data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "    labels, features_n = targetFeatureSplit(data)\n",
    "    K_best_n = SelectKBest(k=n)\n",
    "    features_Kbest_n = K_best_n.fit_transform(features_n, labels)\n",
    "\n",
    "    features_train1, features_test1, labels_train1, labels_test1 = cross_validation.train_test_split(features_Kbest_n, labels, test_size=0.1, random_state=42)\n",
    "    features_train3, features_test3, labels_train3, labels_test3 = cross_validation.train_test_split(features_Kbest_n, labels, test_size=0.3, random_state=42)\n",
    "    features_train5, features_test5, labels_train5, labels_test5 = cross_validation.train_test_split(features_Kbest_n, labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    print\n",
    "    ts1 = class_run_KNN(features_train1, labels_train1, features_test1, labels_test1)\n",
    "    ts3 = class_run_KNN(features_train3, labels_train3, features_test3, labels_test3)\n",
    "    ts5 = class_run_KNN(features_train5, labels_train5, features_test5, labels_test5)\n",
    "    \n",
    "    print_it(\"KNN: 0.1 test size\",ts5)\n",
    "    print_it(\"KNN: 0.3 test size\",ts5)\n",
    "    print_it(\"KNN: 0.5 test size\",ts5)\n",
    "    \n",
    "    acc.append(ts5[\"Accuracy\"])\n",
    "    precision.append(ts5[\"Recall\"])\n",
    "    recall.append(ts5[\"Precision\"])\n",
    "    f1.append(ts5[\"F1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies\n",
      "[0.9242424242424242, 0.9242424242424242, 0.9242424242424242, 0.9242424242424242, 0.9242424242424242, 0.9242424242424242, 0.9242424242424242, 0.9242424242424242, 0.87878787878787878]\n",
      "Precisions\n",
      "[0.59999999999999998, 0.59999999999999998, 0.59999999999999998, 0.59999999999999998, 0.59999999999999998, 0.59999999999999998, 0.59999999999999998, 0.59999999999999998, 0.375]\n",
      "Recalls\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "F1s\n",
      "[0.54545454545454541, 0.54545454545454541, 0.54545454545454541, 0.54545454545454541, 0.54545454545454541, 0.54545454545454541, 0.54545454545454541, 0.54545454545454541, 0.42857142857142855]\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracies\"\n",
    "print acc\n",
    "print \"Precisions\"\n",
    "print precision\n",
    "print \"Recalls\"\n",
    "print recall\n",
    "print \"F1s\"\n",
    "print f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "# Example starting point. Try investigating other evaluation techniques!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 gridSearchCSVs on KNN, evaluating by F1 score\n",
    "Of these 10 searches, I got the following two classifiers, 5 times each\n",
    "Classifier 1\n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=3, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=1, p=1,\n",
    "           weights='uniform')        \n",
    "F1 = 0.45\n",
    "\n",
    "Classifier 2\n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=3, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=1, p=1,\n",
    "           weights='uniform')        \n",
    "F1 = 0.37\n",
    "\n",
    "## All 10 features, test size 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertlee/anaconda/envs/py2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN\n",
      "Pipeline(steps=[('scaling', MinMaxScaler(copy=True, feature_range=(0, 1))), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=3, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=1,\n",
      "           weights='uniform'))])\n",
      "{'knn__leaf_size': 3, 'knn__algorithm': 'auto', 'knn__n_neighbors': 1, 'knn__p': 1}\n",
      "0.371892385392\n",
      "make_scorer(f1_score)\n"
     ]
    }
   ],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "knn =  KNeighborsClassifier()\n",
    "scaler = MinMaxScaler()\n",
    "sss = StratifiedShuffleSplit(n_splits = 100, test_size=0.3,random_state=42)\n",
    "\n",
    "pipe = Pipeline(steps=[('scaling', scaler), (\"knn\", knn)])\n",
    "\n",
    "param_grid = {\"knn__n_neighbors\": [1, 3, 5, 8, 10, 12, 14],\n",
    "              \"knn__algorithm\": [\"auto\",\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "              \"knn__leaf_size\": range(3,10,1),\n",
    "              \"knn__p\": [1,2]\n",
    "             }\n",
    "\n",
    "knnclf = GridSearchCV(pipe, param_grid, scoring='f1', cv=sss)\n",
    "knnclf.fit(features, labels)\n",
    "bestknn = knnclf.best_estimator_\n",
    "bestparams = knnclf.best_params_\n",
    "bestscore = knnclf.best_score_\n",
    "bestscorer = knnclf.scorer_\n",
    "bestcv = knnclf.cv_results_\n",
    "print \"Best KNN\"\n",
    "print bestknn\n",
    "print bestparams\n",
    "print bestscore\n",
    "print bestscorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_classifier issue\n",
    "I then tried using test_classifier method from tester.py. I reduced the number of folds from 1000 to 10, but it still was running after 5 minutes, so I think something is wrong.\n",
    "\n",
    "print test_classifier(knnclf, my_dataset, features_list)\n",
    "\n",
    "So instead below I test the classifier three times with different test sizes. The results look adequate, but I guess I need you to run the tester on my final classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Above Classifier\n",
      "\n",
      "Testing on 0.1 of sample\n",
      "accuracy 0.785714285714\n",
      "precision 0.333333333333\n",
      "recall 0.5\n",
      "F1 0.4\n",
      "\n",
      "Testing on 0.3 of sample\n",
      "accuracy 0.825\n",
      "precision 0.5\n",
      "recall 0.428571428571\n",
      "F1 0.461538461538\n",
      "\n",
      "Testing on 0.5 of sample\n",
      "accuracy 0.818181818182\n",
      "precision 0.5\n",
      "recall 0.25\n",
      "F1 0.333333333333\n"
     ]
    }
   ],
   "source": [
    "best = KNeighborsClassifier(algorithm='auto', leaf_size=3, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=1, p=1,\n",
    "           weights='uniform')\n",
    "\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "features_train1, features_test1, labels_train1, labels_test1 = cross_validation.train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "features_train3, features_test3, labels_train3, labels_test3 = cross_validation.train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "features_train5, features_test5, labels_train5, labels_test5 = cross_validation.train_test_split(features, labels, test_size=0.5, random_state=42)\n",
    "\n",
    "print \"Testing Above Classifier\"\n",
    "print\n",
    "best.fit(features_train1, labels_train1)\n",
    "pred = best.predict(features_test1)\n",
    "print \"Testing on 0.1 of sample\"\n",
    "print \"accuracy\",accuracy_score(pred,labels_test1)\n",
    "print \"precision\",precision_score(pred,labels_test1)\n",
    "print \"recall\",recall_score(pred,labels_test1)\n",
    "print \"F1\",f1_score(pred,labels_test1)\n",
    "print\n",
    "\n",
    "best.fit(features_train3, labels_train3)\n",
    "pred = best.predict(features_test3)\n",
    "print \"Testing on 0.3 of sample\"\n",
    "print \"accuracy\",accuracy_score(pred,labels_test3)\n",
    "print \"precision\",precision_score(pred,labels_test3)\n",
    "print \"recall\",recall_score(pred,labels_test3)\n",
    "print \"F1\",f1_score(pred,labels_test3)\n",
    "print\n",
    "\n",
    "best.fit(features_train5, labels_train5)\n",
    "pred = best.predict(features_test5)\n",
    "print \"Testing on 0.5 of sample\"\n",
    "print \"accuracy\",accuracy_score(pred,labels_test5)\n",
    "print \"precision\",precision_score(pred,labels_test5)\n",
    "print \"recall\",recall_score(pred,labels_test5)\n",
    "print \"F1\",f1_score(pred,labels_test5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All 10 features, test size 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN\n",
      "Pipeline(steps=[('scaling', MinMaxScaler(copy=True, feature_range=(0, 1))), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=3, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform'))])\n",
      "{'knn__leaf_size': 3, 'knn__algorithm': 'auto', 'knn__n_neighbors': 1, 'knn__p': 2}\n",
      "0.446904761905\n",
      "make_scorer(f1_score)\n"
     ]
    }
   ],
   "source": [
    "knn =  KNeighborsClassifier()\n",
    "scaler = MinMaxScaler()\n",
    "sss = StratifiedShuffleSplit(n_splits = 100, test_size=0.1,random_state=42)\n",
    "\n",
    "pipe = Pipeline(steps=[('scaling', scaler), (\"knn\", knn)])\n",
    "\n",
    "param_grid = {\"knn__n_neighbors\": [1, 3, 5, 8, 10, 12, 14],\n",
    "              \"knn__algorithm\": [\"auto\",\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "              \"knn__leaf_size\": range(3,10,1),\n",
    "              \"knn__p\": [1,2]\n",
    "             }\n",
    "\n",
    "knnclf = GridSearchCV(pipe, param_grid, scoring='f1', cv=sss)\n",
    "knnclf.fit(features, labels)\n",
    "bestknn = knnclf.best_estimator_\n",
    "bestparams = knnclf.best_params_\n",
    "bestscore = knnclf.best_score_\n",
    "bestscorer = knnclf.scorer_\n",
    "bestcv = knnclf.cv_results_\n",
    "print \"Best KNN\"\n",
    "print bestknn\n",
    "print bestparams\n",
    "print bestscore\n",
    "print bestscorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Above Classifier\n",
      "\n",
      "Testing on 0.1 of sample\n",
      "accuracy 0.785714285714\n",
      "precision 0.333333333333\n",
      "recall 0.5\n",
      "F1 0.4\n",
      "\n",
      "Testing on 0.3 of sample\n",
      "accuracy 0.825\n",
      "precision 0.5\n",
      "recall 0.428571428571\n",
      "F1 0.461538461538\n",
      "\n",
      "Testing on 0.5 of sample\n",
      "accuracy 0.818181818182\n",
      "precision 0.5\n",
      "recall 0.25\n",
      "F1 0.333333333333\n"
     ]
    }
   ],
   "source": [
    "best = KNeighborsClassifier(algorithm='auto', leaf_size=3, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
    "           weights='uniform')\n",
    "\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "features_train1, features_test1, labels_train1, labels_test1 = cross_validation.train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "features_train3, features_test3, labels_train3, labels_test3 = cross_validation.train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "features_train5, features_test5, labels_train5, labels_test5 = cross_validation.train_test_split(features, labels, test_size=0.5, random_state=42)\n",
    "\n",
    "print \"Testing Above Classifier\"\n",
    "print\n",
    "best.fit(features_train1, labels_train1)\n",
    "pred = best.predict(features_test1)\n",
    "print \"Testing on 0.1 of sample\"\n",
    "print \"accuracy\",accuracy_score(pred,labels_test1)\n",
    "print \"precision\",precision_score(pred,labels_test1)\n",
    "print \"recall\",recall_score(pred,labels_test1)\n",
    "print \"F1\",f1_score(pred,labels_test1)\n",
    "print\n",
    "\n",
    "best.fit(features_train3, labels_train3)\n",
    "pred = best.predict(features_test3)\n",
    "print \"Testing on 0.3 of sample\"\n",
    "print \"accuracy\",accuracy_score(pred,labels_test3)\n",
    "print \"precision\",precision_score(pred,labels_test3)\n",
    "print \"recall\",recall_score(pred,labels_test3)\n",
    "print \"F1\",f1_score(pred,labels_test3)\n",
    "print\n",
    "\n",
    "best.fit(features_train5, labels_train5)\n",
    "pred = best.predict(features_test5)\n",
    "print \"Testing on 0.5 of sample\"\n",
    "print \"accuracy\",accuracy_score(pred,labels_test5)\n",
    "print \"precision\",precision_score(pred,labels_test5)\n",
    "print \"recall\",recall_score(pred,labels_test5)\n",
    "print \"F1\",f1_score(pred,labels_test5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 best features, test size 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN\n",
      "Pipeline(steps=[('scaling', MinMaxScaler(copy=True, feature_range=(0, 1))), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=3, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=1,\n",
      "           weights='uniform'))])\n",
      "{'knn__leaf_size': 3, 'knn__algorithm': 'auto', 'knn__n_neighbors': 1, 'knn__p': 1}\n",
      "0.371892385392\n",
      "make_scorer(f1_score)\n"
     ]
    }
   ],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "K_best = SelectKBest(k=5)\n",
    "features_kbest = K_best.fit_transform(features, labels)\n",
    "\n",
    "knn =  KNeighborsClassifier()\n",
    "scaler = MinMaxScaler()\n",
    "sss = StratifiedShuffleSplit(n_splits = 100, test_size=0.3,random_state=42)\n",
    " \n",
    "pipe = Pipeline(steps=[('scaling', scaler), (\"knn\", knn)])\n",
    "\n",
    "param_grid = {\"knn__n_neighbors\": [1, 3, 5, 8, 10, 12, 14],\n",
    "              \"knn__algorithm\": [\"auto\",\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "              \"knn__leaf_size\": range(3,10,1),\n",
    "              \"knn__p\": [1,2]\n",
    "             }\n",
    "\n",
    "knnclf = GridSearchCV(pipe, param_grid, scoring='f1', cv=sss)\n",
    "knnclf.fit(features, labels)\n",
    "bestknn = knnclf.best_estimator_\n",
    "bestparams = knnclf.best_params_\n",
    "bestscore = knnclf.best_score_\n",
    "bestscorer = knnclf.scorer_\n",
    "bestcv = knnclf.cv_results_\n",
    "print \"Best KNN\"\n",
    "print bestknn\n",
    "print bestparams\n",
    "print bestscore\n",
    "print bestscorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 best features, test size 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN\n",
      "Pipeline(steps=[('scaling', MinMaxScaler(copy=True, feature_range=(0, 1))), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=3, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform'))])\n",
      "{'knn__leaf_size': 3, 'knn__algorithm': 'auto', 'knn__n_neighbors': 1, 'knn__p': 2}\n",
      "0.446904761905\n",
      "make_scorer(f1_score)\n"
     ]
    }
   ],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "K_best = SelectKBest(k=5)\n",
    "features_kbest = K_best.fit_transform(features, labels)\n",
    "\n",
    "knn =  KNeighborsClassifier()\n",
    "scaler = MinMaxScaler()\n",
    "sss = StratifiedShuffleSplit(n_splits = 100, test_size=0.1,random_state=42)\n",
    " \n",
    "pipe = Pipeline(steps=[('scaling', scaler), (\"knn\", knn)])\n",
    "\n",
    "param_grid = {\"knn__n_neighbors\": [1, 3, 5, 8, 10, 12, 14],\n",
    "              \"knn__algorithm\": [\"auto\",\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "              \"knn__leaf_size\": range(3,10,1),\n",
    "              \"knn__p\": [1,2]\n",
    "             }\n",
    "\n",
    "knnclf = GridSearchCV(pipe, param_grid, scoring='f1', cv=sss)\n",
    "knnclf.fit(features, labels)\n",
    "bestknn = knnclf.best_estimator_\n",
    "bestparams = knnclf.best_params_\n",
    "bestscore = knnclf.best_score_\n",
    "bestscorer = knnclf.scorer_\n",
    "bestcv = knnclf.cv_results_\n",
    "print \"Best KNN\"\n",
    "print bestknn\n",
    "print bestparams\n",
    "print bestscore\n",
    "print bestscorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 best features, test size 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN\n",
      "Pipeline(steps=[('scaling', MinMaxScaler(copy=True, feature_range=(0, 1))), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=3, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=1,\n",
      "           weights='uniform'))])\n",
      "{'knn__leaf_size': 3, 'knn__algorithm': 'auto', 'knn__n_neighbors': 1, 'knn__p': 1}\n",
      "0.371892385392\n",
      "make_scorer(f1_score)\n"
     ]
    }
   ],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "K_best = SelectKBest(k=3)\n",
    "features_kbest = K_best.fit_transform(features, labels)\n",
    "\n",
    "knn =  KNeighborsClassifier()\n",
    "scaler = MinMaxScaler()\n",
    "sss = StratifiedShuffleSplit(n_splits = 100, test_size=0.3,random_state=42)\n",
    " \n",
    "pipe = Pipeline(steps=[('scaling', scaler), (\"knn\", knn)])\n",
    "\n",
    "param_grid = {\"knn__n_neighbors\": [1, 3, 5, 8, 10, 12, 14],\n",
    "              \"knn__algorithm\": [\"auto\",\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "              \"knn__leaf_size\": range(3,10,1),\n",
    "              \"knn__p\": [1,2]\n",
    "             }\n",
    "\n",
    "knnclf = GridSearchCV(pipe, param_grid, scoring='f1', cv=sss)\n",
    "knnclf.fit(features, labels)\n",
    "bestknn = knnclf.best_estimator_\n",
    "bestparams = knnclf.best_params_\n",
    "bestscore = knnclf.best_score_\n",
    "bestscorer = knnclf.scorer_\n",
    "bestcv = knnclf.cv_results_\n",
    "print \"Best KNN\"\n",
    "print bestknn\n",
    "print bestparams\n",
    "print bestscore\n",
    "print bestscorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 best features, test size 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN\n",
      "Pipeline(steps=[('scaling', MinMaxScaler(copy=True, feature_range=(0, 1))), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=3, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform'))])\n",
      "{'knn__leaf_size': 3, 'knn__algorithm': 'auto', 'knn__n_neighbors': 1, 'knn__p': 2}\n",
      "0.446904761905\n",
      "make_scorer(f1_score)\n"
     ]
    }
   ],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "K_best = SelectKBest(k=3)\n",
    "features_kbest = K_best.fit_transform(features, labels)\n",
    "\n",
    "knn =  KNeighborsClassifier()\n",
    "scaler = MinMaxScaler()\n",
    "sss = StratifiedShuffleSplit(n_splits = 100, test_size=0.1,random_state=42)\n",
    " \n",
    "pipe = Pipeline(steps=[('scaling', scaler), (\"knn\", knn)])\n",
    "\n",
    "param_grid = {\"knn__n_neighbors\": [1, 3, 5, 8, 10, 12, 14],\n",
    "              \"knn__algorithm\": [\"auto\",\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "              \"knn__leaf_size\": range(3,10,1),\n",
    "              \"knn__p\": [1,2]\n",
    "             }\n",
    "\n",
    "knnclf = GridSearchCV(pipe, param_grid, scoring='f1', cv=sss)\n",
    "knnclf.fit(features, labels)\n",
    "bestknn = knnclf.best_estimator_\n",
    "bestparams = knnclf.best_params_\n",
    "bestscore = knnclf.best_score_\n",
    "bestscorer = knnclf.scorer_\n",
    "bestcv = knnclf.cv_results_\n",
    "print \"Best KNN\"\n",
    "print bestknn\n",
    "print bestparams\n",
    "print bestscore\n",
    "print bestscorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 best features, test size 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN\n",
      "Pipeline(steps=[('scaling', MinMaxScaler(copy=True, feature_range=(0, 1))), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=3, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=1,\n",
      "           weights='uniform'))])\n",
      "{'knn__leaf_size': 3, 'knn__algorithm': 'auto', 'knn__n_neighbors': 1, 'knn__p': 1}\n",
      "0.371892385392\n",
      "make_scorer(f1_score)\n"
     ]
    }
   ],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "K_best = SelectKBest(k=1)\n",
    "features_kbest = K_best.fit_transform(features, labels)\n",
    "\n",
    "knn =  KNeighborsClassifier()\n",
    "scaler = MinMaxScaler()\n",
    "sss = StratifiedShuffleSplit(n_splits = 100, test_size=0.3,random_state=42)\n",
    " \n",
    "pipe = Pipeline(steps=[('scaling', scaler), (\"knn\", knn)])\n",
    "\n",
    "param_grid = {\"knn__n_neighbors\": [1, 3, 5, 8, 10, 12, 14],\n",
    "              \"knn__algorithm\": [\"auto\",\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "              \"knn__leaf_size\": range(3,10,1),\n",
    "              \"knn__p\": [1,2]\n",
    "             }\n",
    "\n",
    "knnclf = GridSearchCV(pipe, param_grid, scoring='f1', cv=sss)\n",
    "knnclf.fit(features, labels)\n",
    "bestknn = knnclf.best_estimator_\n",
    "bestparams = knnclf.best_params_\n",
    "bestscore = knnclf.best_score_\n",
    "bestscorer = knnclf.scorer_\n",
    "bestcv = knnclf.cv_results_\n",
    "print \"Best KNN\"\n",
    "print bestknn\n",
    "print bestparams\n",
    "print bestscore\n",
    "print bestscorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 best features, test size 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN\n",
      "Pipeline(steps=[('scaling', MinMaxScaler(copy=True, feature_range=(0, 1))), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=3, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform'))])\n",
      "{'knn__leaf_size': 3, 'knn__algorithm': 'auto', 'knn__n_neighbors': 1, 'knn__p': 2}\n",
      "0.446904761905\n",
      "make_scorer(f1_score)\n"
     ]
    }
   ],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "K_best = SelectKBest(k=1)\n",
    "features_kbest = K_best.fit_transform(features, labels)\n",
    "\n",
    "knn =  KNeighborsClassifier()\n",
    "scaler = MinMaxScaler()\n",
    "sss = StratifiedShuffleSplit(n_splits = 100, test_size=0.1,random_state=42)\n",
    " \n",
    "pipe = Pipeline(steps=[('scaling', scaler), (\"knn\", knn)])\n",
    "\n",
    "param_grid = {\"knn__n_neighbors\": [1, 3, 5, 8, 10, 12, 14],\n",
    "              \"knn__algorithm\": [\"auto\",\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "              \"knn__leaf_size\": range(3,10,1),\n",
    "              \"knn__p\": [1,2]\n",
    "             }\n",
    "\n",
    "knnclf = GridSearchCV(pipe, param_grid, scoring='f1', cv=sss)\n",
    "knnclf.fit(features, labels)\n",
    "bestknn = knnclf.best_estimator_\n",
    "bestparams = knnclf.best_params_\n",
    "bestscore = knnclf.best_score_\n",
    "bestscorer = knnclf.scorer_\n",
    "bestcv = knnclf.cv_results_\n",
    "print \"Best KNN\"\n",
    "print bestknn\n",
    "print bestparams\n",
    "print bestscore\n",
    "print bestscorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier() with DecisionTreeClassifier()\n",
    "F1 = 0.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ada\n",
      "Pipeline(steps=[('scaling', MinMaxScaler(copy=True, feature_range=(0, 1))), ('ada', AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impur...dom_state=42, splitter='random'),\n",
      "          learning_rate=1.0, n_estimators=10, random_state=None))])\n",
      "{'ada__base_estimator__splitter': 'random', 'ada__n_estimators': 10, 'ada__base_estimator__criterion': 'entropy'}\n",
      "0.324214285714\n",
      "make_scorer(f1_score)\n"
     ]
    }
   ],
   "source": [
    "DTC = DecisionTreeClassifier(random_state = 42, max_features = \"auto\", class_weight = \"balanced\",max_depth = None)\n",
    "ada = AdaBoostClassifier(base_estimator=DTC)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "sss = StratifiedShuffleSplit(n_splits = 100, test_size=0.1,random_state=42)\n",
    "\n",
    "pipe = Pipeline(steps=[('scaling',scaler),(\"ada\", ada)])\n",
    "\n",
    "param_grid = {\"ada__base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "              \"ada__base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "              \"ada__n_estimators\": [1, 10, 50, 100, 200]\n",
    "             }\n",
    "     \n",
    "adaclf = GridSearchCV(pipe, param_grid, scoring='f1', cv=sss)\n",
    "adaclf.fit(features, labels)\n",
    "bestada = adaclf.best_estimator_\n",
    "bestparams = adaclf.best_params_\n",
    "bestscore = adaclf.best_score_\n",
    "bestscorer = adaclf.scorer_\n",
    "bestcv = adaclf.cv_results_\n",
    "print \"Best Ada\"\n",
    "print bestada\n",
    "print bestparams\n",
    "print bestscore\n",
    "print bestscorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier() with GaussianNB()\n",
    "F1 = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertlee/anaconda/envs/py2/lib/python2.7/site-packages/sklearn/naive_bayes.py:232: RuntimeWarning: invalid value encountered in divide\n",
      "  new_mu = np.average(X, axis=0, weights=sample_weight / n_new)\n",
      "/Users/robertlee/anaconda/envs/py2/lib/python2.7/site-packages/sklearn/naive_bayes.py:234: RuntimeWarning: invalid value encountered in divide\n",
      "  weights=sample_weight / n_new)\n",
      "/Users/robertlee/anaconda/envs/py2/lib/python2.7/site-packages/sklearn/naive_bayes.py:427: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/Users/robertlee/anaconda/envs/py2/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:519: RuntimeWarning: invalid value encountered in less\n",
      "  proba[proba < np.finfo(proba.dtype).eps] = np.finfo(proba.dtype).eps\n",
      "/Users/robertlee/anaconda/envs/py2/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:288: RuntimeWarning: invalid value encountered in less\n",
      "  proba[proba < np.finfo(proba.dtype).eps] = np.finfo(proba.dtype).eps\n",
      "/Users/robertlee/anaconda/envs/py2/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:603: RuntimeWarning: invalid value encountered in greater\n",
      "  return self.classes_.take(pred > 0, axis=0)\n",
      "/Users/robertlee/anaconda/envs/py2/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:531: RuntimeWarning: invalid value encountered in less\n",
      "  (estimator_weight < 0)))\n",
      "/Users/robertlee/anaconda/envs/py2/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:530: RuntimeWarning: invalid value encountered in greater\n",
      "  ((sample_weight > 0) |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ada\n",
      "Pipeline(steps=[('scaling', MinMaxScaler(copy=True, feature_range=(0, 1))), ('ada', AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=GaussianNB(priors=None), learning_rate=1.0,\n",
      "          n_estimators=1, random_state=None))])\n",
      "{'ada__n_estimators': 1}\n",
      "0.253238095238\n",
      "make_scorer(f1_score)\n"
     ]
    }
   ],
   "source": [
    "NB = GaussianNB()\n",
    "adaN = AdaBoostClassifier(base_estimator=NB)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "sss = StratifiedShuffleSplit(n_splits = 100, test_size=0.1,random_state=42)\n",
    "\n",
    "pipe = Pipeline(steps=[('scaling',scaler),(\"ada\", adaN)])\n",
    "\n",
    "param_grid = {\n",
    "              \"ada__n_estimators\": [1, 10, 50, 100, 200]\n",
    "             }\n",
    "     \n",
    "adaclf = GridSearchCV(pipe, param_grid, scoring='f1', cv=sss)\n",
    "adaclf.fit(features, labels)\n",
    "bestada = adaclf.best_estimator_\n",
    "bestparams = adaclf.best_params_\n",
    "bestscore = adaclf.best_score_\n",
    "bestscorer = adaclf.scorer_\n",
    "bestcv = adaclf.cv_results_\n",
    "print \"Best Ada\"\n",
    "print bestada\n",
    "print bestparams\n",
    "print bestscore\n",
    "print bestscorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumping classifer, dataset, and feature_list to .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = best\n",
    "CLF_PICKLE_FILENAME = \"my_classifier.pkl\"\n",
    "DATASET_PICKLE_FILENAME = \"my_dataset.pkl\"\n",
    "FEATURE_LIST_FILENAME = \"my_feature_list.pkl\"\n",
    "\n",
    "def dump_classifier_and_data(clf, dataset, feature_list):\n",
    "    with open(CLF_PICKLE_FILENAME, \"w\") as clf_outfile:\n",
    "        pickle.dump(clf, clf_outfile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"w\") as dataset_outfile:\n",
    "        pickle.dump(dataset, dataset_outfile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"w\") as featurelist_outfile:\n",
    "        pickle.dump(feature_list, featurelist_outfile)\n",
    "        \n",
    "dump_classifier_and_data(bestknn, data_dict, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Checking the written files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"my_classifier.pkl\", \"r\") as file:\n",
    "    clf = pickle.load(file)\n",
    "print clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"my_dataset.pkl\", \"r\") as file:\n",
    "    data = pickle.load(file)\n",
    "for person in data:\n",
    "    print person, data[person]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"my_feature_list.pkl\", \"r\") as file:\n",
    "    features = pickle.load(file)\n",
    "print features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py2]",
   "language": "python",
   "name": "Python [py2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
